{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dbscan_G.231.19.0142.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP6Vy+HfYnuT6DLBbKgju8q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"-T6Oum7eyAcx","executionInfo":{"status":"ok","timestamp":1637287198970,"user_tz":-420,"elapsed":1470,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#load libraries\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn import datasets\n","#import train_test_split function\n","from sklearn.model_selection import train_test_split\n","#import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"SusKOowXyRdZ","executionInfo":{"status":"ok","timestamp":1637287198974,"user_tz":-420,"elapsed":26,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#load data\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"cM_LdiXiyXOS","executionInfo":{"status":"ok","timestamp":1637287198976,"user_tz":-420,"elapsed":27,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#split dataset into training set and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXXfHOyPyb7Y","executionInfo":{"status":"ok","timestamp":1637287198977,"user_tz":-420,"elapsed":28,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#create adaboost classifier object\n","abc = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n","#training adaboost classifier\n","model = abc.fit(X_train, y_train)\n","#predict the response for test dataset\n","y_pred = model.predict(X_test)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSIPcrWSyeHX","executionInfo":{"status":"ok","timestamp":1637287198978,"user_tz":-420,"elapsed":27,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}},"outputId":"62aeffaf-cb68-4c5b-a0fa-ec0a96e026f2"},"source":["#model accuracy, how often is the classifier correct?\n","print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9333333333333333\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xzzHzgUylKy","executionInfo":{"status":"ok","timestamp":1637287201077,"user_tz":-420,"elapsed":2122,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}},"outputId":"33adbce5-097f-433c-b74b-eab2ff9df653"},"source":["!git clone https://github.com/eriklindernoren/ML-From-Scratch"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ML-From-Scratch'...\n","remote: Enumerating objects: 2558, done.\u001b[K\n","remote: Total 2558 (delta 0), reused 0 (delta 0), pack-reused 2558\u001b[K\n","Receiving objects: 100% (2558/2558), 553.45 KiB | 1.58 MiB/s, done.\n","Resolving deltas: 100% (1960/1960), done.\n"]}]},{"cell_type":"code","metadata":{"id":"muX3Z9ZSylAv","executionInfo":{"status":"ok","timestamp":1637287201080,"user_tz":-420,"elapsed":12,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["import sys\n","sys.path.append('/content/ML-From-Scratch')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUp3ZVGuzND3","executionInfo":{"status":"ok","timestamp":1637287284645,"user_tz":-420,"elapsed":622,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["from __future__ import print_function, division\n","import numpy as np\n","from mlfromscratch.utils import Plot, euclidean_distance, normalize\n","\n","\n","class DBSCAN():\n","    \"\"\"A density based clustering method that expands clusters from \n","    samples that have more neighbors within a radius specified by eps\n","    than the value min_samples.\n","\n","    Parameters:\n","    -----------\n","    eps: float\n","        The radius within which samples are considered neighbors\n","    min_samples: int\n","        The number of neighbors required for the sample to be a core point. \n","    \"\"\"\n","    def __init__(self, eps=1, min_samples=5):\n","        self.eps = eps\n","        self.min_samples = min_samples\n","\n","    def _get_neighbors(self, sample_i):\n","        \"\"\" Return a list of indexes of neighboring samples\n","        A sample_2 is considered a neighbor of sample_1 if the distance between\n","        them is smaller than epsilon \"\"\"\n","        neighbors = []\n","        idxs = np.arange(len(self.X))\n","        for i, _sample in enumerate(self.X[idxs != sample_i]):\n","            distance = euclidean_distance(self.X[sample_i], _sample)\n","            if distance < self.eps:\n","                neighbors.append(i)\n","        return np.array(neighbors)\n","\n","    def _expand_cluster(self, sample_i, neighbors):\n","        \"\"\" Recursive method which expands the cluster until we have reached the border\n","        of the dense area (density determined by eps and min_samples) \"\"\"\n","        cluster = [sample_i]\n","        # Iterate through neighbors\n","        for neighbor_i in neighbors:\n","            if not neighbor_i in self.visited_samples:\n","                self.visited_samples.append(neighbor_i)\n","                # Fetch the sample's distant neighbors (neighbors of neighbor)\n","                self.neighbors[neighbor_i] = self._get_neighbors(neighbor_i)\n","                # Make sure the neighbor's neighbors are more than min_samples\n","                # (If this is true the neighbor is a core point)\n","                if len(self.neighbors[neighbor_i]) >= self.min_samples:\n","                    # Expand the cluster from the neighbor\n","                    expanded_cluster = self._expand_cluster(\n","                        neighbor_i, self.neighbors[neighbor_i])\n","                    # Add expanded cluster to this cluster\n","                    cluster = cluster + expanded_cluster\n","                else:\n","                    # If the neighbor is not a core point we only add the neighbor point\n","                    cluster.append(neighbor_i)\n","        return cluster\n","\n","    def _get_cluster_labels(self):\n","        \"\"\" Return the samples labels as the index of the cluster in which they are\n","        contained \"\"\"\n","        # Set default value to number of clusters\n","        # Will make sure all outliers have same cluster label\n","        labels = np.full(shape=self.X.shape[0], fill_value=len(self.clusters))\n","        for cluster_i, cluster in enumerate(self.clusters):\n","            for sample_i in cluster:\n","                labels[sample_i] = cluster_i\n","        return labels\n","\n","    # DBSCAN\n","    def predict(self, X):\n","        self.X = X\n","        self.clusters = []\n","        self.visited_samples = []\n","        self.neighbors = {}\n","        n_samples = np.shape(self.X)[0]\n","        # Iterate through samples and expand clusters from them\n","        # if they have more neighbors than self.min_samples\n","        for sample_i in range(n_samples):\n","            if sample_i in self.visited_samples:\n","                continue\n","            self.neighbors[sample_i] = self._get_neighbors(sample_i)\n","            if len(self.neighbors[sample_i]) >= self.min_samples:\n","                # If core point => mark as visited\n","                self.visited_samples.append(sample_i)\n","                # Sample has more neighbors than self.min_samples => expand\n","                # cluster from sample\n","                new_cluster = self._expand_cluster(\n","                    sample_i, self.neighbors[sample_i])\n","                # Add cluster to list of clusters\n","                self.clusters.append(new_cluster)\n","\n","        # Get the resulting cluster labels\n","        cluster_labels = self._get_cluster_labels()\n","        return cluster_labels\n"],"execution_count":11,"outputs":[]}]}