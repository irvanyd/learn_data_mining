{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fp_growth_G.231.19.0142.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/ANHJqRFJhL8am0MqeIDi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"-T6Oum7eyAcx","executionInfo":{"status":"ok","timestamp":1637287104581,"user_tz":-420,"elapsed":22,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#load libraries\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn import datasets\n","#import train_test_split function\n","from sklearn.model_selection import train_test_split\n","#import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"SusKOowXyRdZ","executionInfo":{"status":"ok","timestamp":1637287104583,"user_tz":-420,"elapsed":18,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#load data\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"cM_LdiXiyXOS","executionInfo":{"status":"ok","timestamp":1637287104585,"user_tz":-420,"elapsed":15,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#split dataset into training set and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXXfHOyPyb7Y","executionInfo":{"status":"ok","timestamp":1637287105175,"user_tz":-420,"elapsed":603,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["#create adaboost classifier object\n","abc = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n","#training adaboost classifier\n","model = abc.fit(X_train, y_train)\n","#predict the response for test dataset\n","y_pred = model.predict(X_test)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSIPcrWSyeHX","executionInfo":{"status":"ok","timestamp":1637287105176,"user_tz":-420,"elapsed":31,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}},"outputId":"852c9c37-fc9f-4ff5-cfdc-403085bfbfbc"},"source":["#model accuracy, how often is the classifier correct?\n","print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9555555555555556\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xzzHzgUylKy","executionInfo":{"status":"ok","timestamp":1637287105177,"user_tz":-420,"elapsed":26,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}},"outputId":"8dc1a0f3-6c00-4255-81bc-53b88de41046"},"source":["!git clone https://github.com/eriklindernoren/ML-From-Scratch"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'ML-From-Scratch' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","metadata":{"id":"muX3Z9ZSylAv","executionInfo":{"status":"ok","timestamp":1637287105178,"user_tz":-420,"elapsed":19,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["import sys\n","sys.path.append('/content/ML-From-Scratch')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUp3ZVGuzND3","executionInfo":{"status":"ok","timestamp":1637287105179,"user_tz":-420,"elapsed":19,"user":{"displayName":"irvan yudha andika","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUIlzrJ9OXIaoOtpuog6eTKFdxzzVIAqtptr1FzQ=s64","userId":"15130068374451695055"}}},"source":["from __future__ import division, print_function\n","import numpy as np\n","import itertools\n","\n","\n","class FPTreeNode():\n","    def __init__(self, item=None, support=1):\n","        # 'Value' of the item\n","        self.item = item\n","        # Number of times the item occurs in a\n","        # transaction\n","        self.support = support\n","        # Child nodes in the FP Growth Tree\n","        self.children = {}\n","\n","\n","class FPGrowth():\n","    \"\"\"A method for determining frequent itemsets in a transactional database. \n","    This is done by building a so called FP Growth tree, which can then be mined\n","    to collect the frequent itemsets. More effective than Apriori for large transactional\n","    databases.\n","\n","    Parameters:\n","    -----------\n","    min_sup: float\n","        The minimum fraction of transactions an itemets needs to\n","        occur in to be deemed frequent\n","    \"\"\"\n","    def __init__(self, min_sup=0.3):\n","        self.min_sup = min_sup\n","        # The root of the initial FP Growth Tree\n","        self.tree_root = None\n","        # Prefixes of itemsets in the FP Growth Tree\n","        self.prefixes = {}\n","        self.frequent_itemsets = []\n","\n","    # Count the number of transactions that contains item.\n","    def _calculate_support(self, item, transactions):\n","        count = 0\n","        for transaction in transactions:\n","            if item in transaction:\n","                count += 1\n","        support = count\n","        return support\n","\n","\n","    def _get_frequent_items(self, transactions):\n","        \"\"\" Returns a set of frequent items. An item is determined to\n","        be frequent if there are atleast min_sup transactions that contains\n","        it. \"\"\"\n","        # Get all unique items in the transactions\n","        unique_items = set(\n","            item for transaction in transactions for item in transaction)\n","        items = []\n","        for item in unique_items:\n","            sup = self._calculate_support(item, transactions)\n","            if sup >= self.min_sup:\n","                items.append([item, sup])\n","        # Sort by support - Highest to lowest\n","        items.sort(key=lambda item: item[1], reverse=True)\n","        frequent_items = [[el[0]] for el in items]\n","        # Only return the items\n","        return frequent_items\n","\n","    def _insert_tree(self, node, children):\n","        \"\"\" Recursive method which adds nodes to the tree. \"\"\"\n","        if not children:\n","            return\n","        # Create new node as the first item in children list\n","        child_item = children[0]\n","        child = FPTreeNode(item=child_item)\n","        # If parent already contains item => increase the support\n","        if child_item in node.children:\n","            node.children[child.item].support += 1\n","        else:\n","            node.children[child.item] = child\n","\n","        # Execute _insert_tree on the rest of the children list\n","        # from the new node\n","        self._insert_tree(node.children[child.item], children[1:])\n","\n","    def _construct_tree(self, transactions, frequent_items=None):\n","        if not frequent_items:\n","            # Get frequent items sorted by support\n","            frequent_items = self._get_frequent_items(transactions)\n","        unique_frequent_items = list(\n","            set(item for itemset in frequent_items for item in itemset))\n","        # Construct the root of the FP Growth tree\n","        root = FPTreeNode()\n","        for transaction in transactions:\n","            # Remove items that are not frequent according to\n","            # unique_frequent_items\n","            transaction = [item for item in transaction if item in unique_frequent_items]\n","            transaction.sort(key=lambda item: frequent_items.index([item]))\n","            self._insert_tree(root, transaction)\n","\n","        return root\n","\n","    def print_tree(self, node=None, indent_times=0):\n","        \"\"\" Recursive method which prints the FP Growth Tree \"\"\"\n","        if not node:\n","            node = self.tree_root\n","        indent = \"    \" * indent_times\n","        print (\"%s%s:%s\" % (indent, node.item, node.support))\n","        for child_key in node.children:\n","            child = node.children[child_key]\n","            self.print_tree(child, indent_times + 1)\n","\n","\n","    def _is_prefix(self, itemset, node):\n","        \"\"\" Makes sure that the first item in itemset is a child of node \n","        and that every following item in itemset is reachable via that path \"\"\"\n","        for item in itemset:\n","            if not item in node.children:\n","                return False\n","            node = node.children[item]\n","        return True\n","\n","\n","    def _determine_prefixes(self, itemset, node, prefixes=None):\n","        \"\"\" Recursive method that adds prefixes to the itemset by traversing the \n","        FP Growth Tree\"\"\"\n","        if not prefixes:\n","            prefixes = []\n","\n","        # If the current node is a prefix to the itemset\n","        # add the current prefixes value as prefix to the itemset\n","        if self._is_prefix(itemset, node):\n","            itemset_key = self._get_itemset_key(itemset)\n","            if not itemset_key in self.prefixes:\n","                self.prefixes[itemset_key] = []\n","            self.prefixes[itemset_key] += [{\"prefix\": prefixes, \"support\": node.children[itemset[0]].support}]\n","\n","        for child_key in node.children:\n","            child = node.children[child_key]\n","            # Recursive call with child as new node. Add the child item as potential\n","            # prefix.\n","            self._determine_prefixes(itemset, child, prefixes + [child.item])\n","\n","\n","    def _get_itemset_key(self, itemset):\n","        \"\"\" Determines the look of the hashmap key for self.prefixes\n","        List of more strings than one gets joined by '-' \"\"\"\n","        if len(itemset) > 1:\n","            itemset_key = \"-\".join(itemset)\n","        else:\n","            itemset_key = str(itemset[0])\n","        return itemset_key\n","\n","    def _determine_frequent_itemsets(self, conditional_database, suffix):\n","        # Calculate new frequent items from the conditional database\n","        # of suffix\n","        frequent_items = self._get_frequent_items(conditional_database)\n","\n","        cond_tree = None\n","\n","        if suffix:\n","            cond_tree = self._construct_tree(conditional_database, frequent_items)\n","            # Output new frequent itemset as the suffix added to the frequent\n","            # items\n","            self.frequent_itemsets += [el + suffix for el in frequent_items]\n","\n","        # Find larger frequent itemset by finding prefixes\n","        # of the frequent items in the FP Growth Tree for the conditional\n","        # database.\n","        self.prefixes = {}\n","        for itemset in frequent_items:\n","            # If no suffix (first run)\n","            if not cond_tree:\n","                cond_tree = self.tree_root\n","            # Determine prefixes to itemset\n","            self._determine_prefixes(itemset, cond_tree)\n","            conditional_database = []\n","            itemset_key = self._get_itemset_key(itemset)\n","            # Build new conditional database\n","            if itemset_key in self.prefixes:\n","                for el in self.prefixes[itemset_key]:\n","                    # If support = 4 => add 4 of the corresponding prefix set\n","                    for _ in range(el[\"support\"]):\n","                        conditional_database.append(el[\"prefix\"])\n","                # Create new suffix\n","                new_suffix = itemset + suffix if suffix else itemset\n","                self._determine_frequent_itemsets(conditional_database, suffix=new_suffix)\n","\n","    def find_frequent_itemsets(self, transactions, suffix=None, show_tree=False):\n","        self.transactions = transactions\n","\n","        # Build the FP Growth Tree\n","        self.tree_root = self._construct_tree(transactions)\n","        if show_tree:\n","            print (\"FP-Growth Tree:\")\n","            self.print_tree(self.tree_root)\n","\n","        self._determine_frequent_itemsets(transactions, suffix=None)\n","\n","        return self.frequent_itemsets\n","\n"],"execution_count":19,"outputs":[]}]}